<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>rpi-vr-camera WebXR/WebRTC Preview</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
      body {
        margin: 0;
        padding: 0;
        font-family: Arial, sans-serif;
        background: #111;
        color: #eee;
        display: flex;
        flex-direction: column;
        align-items: center;
        gap: 16px;
      }
      header {
        padding: 16px;
        text-align: center;
      }
      .preview {
        display: flex;
        gap: 12px;
        justify-content: center;
        flex-wrap: wrap;
        width: 100%;
      }
      .preview video {
        max-width: 42vw;
        min-width: 280px;
        background: #000;
      }
      .controls {
        display: flex;
        gap: 12px;
        align-items: center;
      }
      button {
        padding: 10px 16px;
        background: #1e88e5;
        border: none;
        color: #fff;
        border-radius: 4px;
        cursor: pointer;
      }
      button:disabled {
        background: #555;
        cursor: not-allowed;
      }
      a {
        color: #90caf9;
      }
      pre {
        max-width: 90vw;
        white-space: pre-wrap;
      }
    </style>
  </head>
  <body>
    <header>
      <h1>rpi-vr-camera WebRTC Preview</h1>
      <p>
        This page negotiates a WebRTC connection with the Raspberry Pi and
        displays the side-by-side stereo feed. For Oculus Quest, open this page
        via <code>https://&lt;pi-ip&gt;:8443</code>. Install the provided CA
        certificate first so the headset trusts the stream.
      </p>
    </header>
    <p id="caSection" style="display:none;">
      <a id="caLink" href="/ca.crt" download>Download CA certificate</a>
      (import under <strong>Settings → Security → Install certificates</strong>)
    </p>
    <div class="controls">
      <button id="startButton">Start Stream</button>
      <button id="stopButton" disabled>Stop</button>
      <button id="enterVrButton" disabled>Enter VR</button>
    </div>
    <div class="preview">
      <video id="leftVideo" playsinline autoplay muted></video>
      <video id="rightVideo" playsinline autoplay muted style="display:none;"></video>
    </div>
    <canvas id="xrCanvas" style="display:none"></canvas>
    <div id="stats">
      <span id="fpsLabel"></span>
    </div>
    <pre id="status"></pre>

    <script>
      const startButton = document.getElementById("startButton");
      const stopButton = document.getElementById("stopButton");
      const enterVrButton = document.getElementById("enterVrButton");
      const leftVideo = document.getElementById("leftVideo");
      const rightVideo = document.getElementById("rightVideo");
      const statusEl = document.getElementById("status");
      const fpsLabel = document.getElementById("fpsLabel");
      const xrCanvas = document.getElementById("xrCanvas");
      const caSection = document.getElementById("caSection");

      if (caSection) {
        fetch("/ca.crt", { method: "HEAD" })
          .then((resp) => {
            if (resp.ok) {
              caSection.style.display = "block";
            }
          })
          .catch(() => {});
      }

      const hasWebXR = !!navigator.xr;

      let pc = null;
      let gl = null;
      let xrSession = null;
      let xrRefSpace = null;
      let leftTexture = null;
      let rightTexture = null;
      let shaderProgram = null;
      let positionBuffer = null;
      let texcoordBuffer = null;
      let attribPosition = null;
      let attribTexCoord = null;
      let uniformTexture = null;
      let leftStream = null;
      let rightStream = null;

      function log(message) {
        statusEl.textContent = message;
      }

      let frameCounter = 0;
      let lastFpsUpdate = performance.now();
      function monitorFps() {
        frameCounter += 1;
        const now = performance.now();
        if (now - lastFpsUpdate >= 1000) {
          const fps = (frameCounter * 1000) / (now - lastFpsUpdate);
          fpsLabel.textContent = `Approx FPS: ${fps.toFixed(1)}`;
          frameCounter = 0;
          lastFpsUpdate = now;
        }
      requestAnimationFrame(monitorFps);
    }
    requestAnimationFrame(monitorFps);

    let statsTimer = null;

    function monitorConnection(connection) {
      if (statsTimer) {
        clearInterval(statsTimer);
      }
      statsTimer = setInterval(async () => {
        if (!connection) {
          return;
        }
        try {
          const stats = await connection.getStats();
          let videoStats = [];
          stats.forEach((report) => {
            if (report.type === "inbound-rtp" && report.kind === "video") {
              videoStats.push(
                `mid=${report.mid || "?"} frames=${report.framesDecoded || 0} bytes=${report.bytesReceived || 0}`
              );
            }
          });
          if (videoStats.length) {
            log(`Video stats: ${videoStats.join(" | ")}`);
          }
        } catch (err) {
          console.warn("getStats failed", err);
        }
      }, 1000);
    }

    async function stopStream(message) {
      stopButton.disabled = true;
      startButton.disabled = false;
      enterVrButton.disabled = true;

        if (xrSession) {
          try {
            await xrSession.end();
          } catch (err) {
            console.warn("XR end error", err);
          }
          xrSession = null;
          xrRefSpace = null;
        }

        if (pc) {
          pc.getSenders().forEach((sender) => sender.track && sender.track.stop());
          await pc.close();
          pc = null;
        }

        if (leftStream) {
          leftStream.getTracks().forEach((track) => track.stop());
        }
        if (rightStream) {
          rightStream.getTracks().forEach((track) => track.stop());
        }
        leftStream = null;
        rightStream = null;

        leftVideo.srcObject = null;
        rightVideo.srcObject = null;
        rightVideo.style.display = "none";
        log(message || "Stream stopped.");
      }

      async function startStream() {
        startButton.disabled = true;
        stopButton.disabled = false;
        log("Starting WebRTC negotiation…");

        leftStream = null;
        rightStream = null;
        leftVideo.srcObject = null;
        rightVideo.srcObject = null;
        rightVideo.style.display = "none";

        pc = new RTCPeerConnection({
          iceServers: [{ urls: ["stun:stun.l.google.com:19302"] }],
        });

        pc.addEventListener("track", (event) => {
          console.log("track event", event.track.kind, event.track.id, event.streams);
          if (event.track.kind !== "video") {
            return;
          }
          const stream = event.streams[0] || new MediaStream([event.track]);
          if (!leftStream) {
            leftStream = stream;
            leftVideo.srcObject = leftStream;
            leftVideo.play().catch((err) => console.warn("left play() failed", err));
            log(`Left track ${event.track.id} attached.`);
          } else if (!rightStream) {
            rightStream = stream;
            rightVideo.srcObject = rightStream;
            rightVideo.style.display = "block";
            rightVideo.play().catch((err) => console.warn("right play() failed", err));
            log(`Right track ${event.track.id} attached.`);
          } else {
            rightStream.getTracks().forEach((track) => track.stop());
            rightStream = stream;
            rightVideo.srcObject = rightStream;
            rightVideo.style.display = "block";
            rightVideo.play().catch((err) => console.warn("right play() failed", err));
            log(`Replaced extra track with ${event.track.id}.`);
          }

          event.track.addEventListener("unmute", () => {
            console.log("track unmute", event.track.id);
          });
          event.track.addEventListener("mute", () => {
            console.log("track mute", event.track.id);
          });
          event.track.addEventListener("ended", () => {
            console.log("track ended", event.track.id);
            if (leftStream && leftStream.getTracks().includes(event.track)) {
              leftStream = null;
              leftVideo.srcObject = null;
            }
            if (rightStream && rightStream.getTracks().includes(event.track)) {
              rightStream = null;
              rightVideo.srcObject = null;
              rightVideo.style.display = "none";
            }
          });
        });

        pc.addEventListener("connectionstatechange", () => {
          log(`Peer connection state: ${pc.connectionState}`);
          if (pc.connectionState === "failed" || pc.connectionState === "closed") {
            stopStream(`Connection ${pc.connectionState}`);
          }
        });

        pc.addTransceiver("video", { direction: "recvonly" });
        pc.addTransceiver("video", { direction: "recvonly" });
        pc.addTransceiver("audio", { direction: "recvonly" });

        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        monitorConnection(pc);

        const fail = async (message) => {
          await stopStream(message);
        };

        let response;
        try {
          response = await fetch("/offer", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(pc.localDescription),
          });
        } catch (err) {
          await fail(`Offer network error: ${err}`);
          return;
        }

        const payload = await response.json().catch(() => ({}));
        if (!response.ok) {
          const message = payload.error || response.statusText;
          await fail(`Offer failed: ${message}`);
          return;
        }

        await pc.setRemoteDescription(payload);
        log("WebRTC connection established.");
        if (hasWebXR) {
          enterVrButton.disabled = false;
        }
      }

      function ensureGl() {
        if (gl) {
          return gl;
        }

        const contextAttributes = { xrCompatible: true, alpha: false };
        gl =
          xrCanvas.getContext("webgl2", contextAttributes) ||
          xrCanvas.getContext("webgl", contextAttributes);

        if (!gl) {
          log("WebGL not available; cannot enter VR.");
          return null;
        }

        const vertexSource = `
          attribute vec2 aPosition;
          attribute vec2 aTexCoord;
          varying vec2 vTexCoord;
          void main() {
            gl_Position = vec4(aPosition, 0.0, 1.0);
            vTexCoord = aTexCoord;
          }
        `;

        const fragmentSource = `
          precision mediump float;
          varying vec2 vTexCoord;
          uniform sampler2D uTexture;
          void main() {
            gl_FragColor = texture2D(uTexture, vTexCoord);
          }
        `;

        const compileShader = (type, source) => {
          const shader = gl.createShader(type);
          gl.shaderSource(shader, source);
          gl.compileShader(shader);
          if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
            const info = gl.getShaderInfoLog(shader);
            gl.deleteShader(shader);
            throw new Error(`Shader compile failed: ${info}`);
          }
          return shader;
        };

        const vertexShader = compileShader(gl.VERTEX_SHADER, vertexSource);
        const fragmentShader = compileShader(gl.FRAGMENT_SHADER, fragmentSource);

        shaderProgram = gl.createProgram();
        gl.attachShader(shaderProgram, vertexShader);
        gl.attachShader(shaderProgram, fragmentShader);
        gl.linkProgram(shaderProgram);
        if (!gl.getProgramParameter(shaderProgram, gl.LINK_STATUS)) {
          const info = gl.getProgramInfoLog(shaderProgram);
          throw new Error(`Program link failed: ${info}`);
        }
        gl.deleteShader(vertexShader);
        gl.deleteShader(fragmentShader);
        gl.useProgram(shaderProgram);

        positionBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        gl.bufferData(
          gl.ARRAY_BUFFER,
          new Float32Array([
            -1, -1,
            1, -1,
            -1, 1,
            -1, 1,
            1, -1,
            1, 1,
          ]),
          gl.STATIC_DRAW
        );
        attribPosition = gl.getAttribLocation(shaderProgram, "aPosition");
        gl.enableVertexAttribArray(attribPosition);
        gl.vertexAttribPointer(attribPosition, 2, gl.FLOAT, false, 0, 0);

        texcoordBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, texcoordBuffer);
        gl.bufferData(
          gl.ARRAY_BUFFER,
          new Float32Array([
            0, 0,
            1, 0,
            0, 1,
            0, 1,
            1, 0,
            1, 1,
          ]),
          gl.STATIC_DRAW
        );
        attribTexCoord = gl.getAttribLocation(shaderProgram, "aTexCoord");
        gl.enableVertexAttribArray(attribTexCoord);
        gl.vertexAttribPointer(attribTexCoord, 2, gl.FLOAT, false, 0, 0);

        uniformTexture = gl.getUniformLocation(shaderProgram, "uTexture");
        gl.uniform1i(uniformTexture, 0);
        gl.activeTexture(gl.TEXTURE0);

        const createTexture = () => {
          const texture = gl.createTexture();
          gl.bindTexture(gl.TEXTURE_2D, texture);
          gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
          gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
          gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
          gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
          gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGB, 2, 2, 0, gl.RGB, gl.UNSIGNED_BYTE, null);
          return texture;
        };

        leftTexture = createTexture();
        rightTexture = createTexture();
        gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);

        gl.clearColor(0, 0, 0, 1);
        gl.disable(gl.DEPTH_TEST);
        gl.disable(gl.CULL_FACE);

        return gl;
      }

      async function enterVR() {
        if (!hasWebXR) {
          log("WebXR not supported in this browser.");
          return;
        }
        const supported = await navigator.xr.isSessionSupported("immersive-vr").catch(() => false);
        if (!supported) {
          log("Immersive VR not available on this device.");
          return;
        }
        const context = ensureGl();
        if (!context) {
          return;
        }
        if (xrSession) {
          await xrSession.end();
        }
        const session = await navigator.xr.requestSession("immersive-vr", {
          optionalFeatures: ["local-floor", "bounded-floor"],
        });
        xrSession = session;

        if (context.makeXRCompatible) {
          await context.makeXRCompatible();
        }
        const glLayer = new XRWebGLLayer(xrSession, context);
        xrSession.updateRenderState({ baseLayer: glLayer });
        xrRefSpace = await xrSession.requestReferenceSpace("local");

        xrSession.addEventListener("end", () => {
          xrSession = null;
          xrRefSpace = null;
          log("VR session ended.");
        });

        xrSession.requestAnimationFrame(onXRFrame);
        log("Entered VR session.");
      }

      function onXRFrame(time, frame) {
        if (!xrSession || !gl) {
          return;
        }
        xrSession.requestAnimationFrame(onXRFrame);
        const pose = frame.getViewerPose(xrRefSpace);
        if (!pose) {
          return;
        }

        const layer = xrSession.renderState.baseLayer;
        gl.bindFramebuffer(gl.FRAMEBUFFER, layer.framebuffer);

        const updateTextureFromVideo = (texture, videoElement) => {
          if (videoElement && videoElement.readyState >= videoElement.HAVE_CURRENT_DATA) {
            gl.bindTexture(gl.TEXTURE_2D, texture);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGB, gl.RGB, gl.UNSIGNED_BYTE, videoElement);
          }
        };

        updateTextureFromVideo(leftTexture, leftVideo);
        if (rightStream) {
          updateTextureFromVideo(rightTexture, rightVideo);
        }

        gl.clear(gl.COLOR_BUFFER_BIT);
        gl.useProgram(shaderProgram);

        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        gl.vertexAttribPointer(attribPosition, 2, gl.FLOAT, false, 0, 0);
        gl.bindBuffer(gl.ARRAY_BUFFER, texcoordBuffer);
        gl.vertexAttribPointer(attribTexCoord, 2, gl.FLOAT, false, 0, 0);

        for (let i = 0; i < pose.views.length; i += 1) {
          const view = pose.views[i];
          const viewport = layer.getViewport(view);
          gl.viewport(viewport.x, viewport.y, viewport.width, viewport.height);
          const useRight = (view.eye && view.eye.toLowerCase() === "right") || i === 1;
          const texture = useRight && rightStream ? rightTexture : leftTexture;
          gl.bindTexture(gl.TEXTURE_2D, texture);
          gl.drawArrays(gl.TRIANGLES, 0, 6);
        }

        gl.bindFramebuffer(gl.FRAMEBUFFER, null);
      }

      startButton.addEventListener("click", startStream);
      stopButton.addEventListener("click", () => stopStream());
      enterVrButton.addEventListener("click", () =>
        enterVR().catch((err) => stopStream(`XR error: ${err}`))
      );
    </script>
  </body>
</html>
